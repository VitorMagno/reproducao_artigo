{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from customCNN import custom_cnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_farm_data(dataset_path, max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Carrega o dataset State Farm (10 classes de distração) que já tem divisão train/test\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: caminho para a pasta state_farm_driver_detection\n",
    "        max_images_per_class: limite de imagens por classe (None = todas)\n",
    "    \n",
    "    Returns:\n",
    "        (X_train, y_train, X_test, y_test): dados de treino e teste\n",
    "    \"\"\"\n",
    "    \n",
    "    def load_images_from_folder(folder_path, max_per_class=None):\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Listar as pastas c0, c1, ..., c9\n",
    "        class_folders = sorted([f for f in os.listdir(folder_path) if f.startswith('c')])\n",
    "        \n",
    "        for class_folder in class_folders:\n",
    "            class_path = os.path.join(folder_path, class_folder)\n",
    "            class_label = int(class_folder[1:])  # Extrai número da classe (c0 -> 0, c1 -> 1, etc.)\n",
    "            \n",
    "            print(f\"Carregando classe {class_label} de {class_path}\")\n",
    "            \n",
    "            # Listar todos os arquivos de imagem\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            # Limitar número de imagens se especificado\n",
    "            if max_per_class is not None:\n",
    "                image_files = image_files[:max_per_class]\n",
    "                print(f\"  -> Limitado a {len(image_files)} imagens por classe\")\n",
    "            \n",
    "            images_loaded = 0\n",
    "            for filename in image_files:\n",
    "                img_path = os.path.join(class_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                if img is not None:\n",
    "                    # Manter formato BGR conforme artigo (sem conversão RGB)\n",
    "                    images.append(img)\n",
    "                    labels.append(class_label)\n",
    "                    images_loaded += 1\n",
    "            \n",
    "            print(f\"  -> {images_loaded} imagens carregadas da classe {class_label}\")\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    # Carregar dados de treino\n",
    "    train_path = os.path.join(dataset_path, 'train')\n",
    "    X_train, y_train = load_images_from_folder(train_path, max_per_class=max_images_per_class)\n",
    "    \n",
    "    # Carregar dados de teste\n",
    "    test_path = os.path.join(dataset_path, 'test')\n",
    "    X_test, y_test = load_images_from_folder(test_path, max_per_class=max_images_per_class)\n",
    "    \n",
    "    print(f\"State Farm - Treino: {X_train.shape}, Teste: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def load_drowsiness_data(dataset_path, test_size=0.2, random_state=42, max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Carrega o dataset de sonolência e faz divisão treino/teste\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: caminho para a pasta driver_drowsiness_dataset\n",
    "        test_size: proporção para teste (default: 0.2 = 20%)\n",
    "        random_state: semente para reprodutibilidade\n",
    "        max_images_per_class: limite de imagens por classe (None = todas)\n",
    "    \n",
    "    Returns:\n",
    "        (X_train, y_train, X_test, y_test): dados de treino e teste\n",
    "    \"\"\"\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Carregar imagens drowsy (classe 1)\n",
    "    drowsy_path = os.path.join(dataset_path, 'drowsy')\n",
    "    print(f\"Carregando imagens drowsy de {drowsy_path}\")\n",
    "    \n",
    "    drowsy_files = [f for f in os.listdir(drowsy_path) \n",
    "                    if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Limitar número de imagens se especificado\n",
    "    if max_images_per_class is not None:\n",
    "        drowsy_files = drowsy_files[:max_images_per_class]\n",
    "        print(f\"  -> Limitado a {len(drowsy_files)} imagens drowsy\")\n",
    "    \n",
    "    drowsy_loaded = 0\n",
    "    for filename in drowsy_files:\n",
    "        img_path = os.path.join(drowsy_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is not None:\n",
    "            # Manter formato BGR conforme artigo (sem conversão RGB)\n",
    "            images.append(img)\n",
    "            labels.append(1)  # drowsy = 1\n",
    "            drowsy_loaded += 1\n",
    "    \n",
    "    print(f\"  -> {drowsy_loaded} imagens drowsy carregadas\")\n",
    "    \n",
    "    # Carregar imagens not_drowsy (classe 0)\n",
    "    not_drowsy_path = os.path.join(dataset_path, 'not_drowsy')\n",
    "    print(f\"Carregando imagens not_drowsy de {not_drowsy_path}\")\n",
    "    \n",
    "    not_drowsy_files = [f for f in os.listdir(not_drowsy_path) \n",
    "                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Limitar número de imagens se especificado\n",
    "    if max_images_per_class is not None:\n",
    "        not_drowsy_files = not_drowsy_files[:max_images_per_class]\n",
    "        print(f\"  -> Limitado a {len(not_drowsy_files)} imagens not_drowsy\")\n",
    "    \n",
    "    not_drowsy_loaded = 0\n",
    "    for filename in not_drowsy_files:\n",
    "        img_path = os.path.join(not_drowsy_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is not None:\n",
    "            # Manter formato BGR conforme artigo (sem conversão RGB)\n",
    "            images.append(img)\n",
    "            labels.append(0)  # not_drowsy = 0\n",
    "            not_drowsy_loaded += 1\n",
    "    \n",
    "    print(f\"  -> {not_drowsy_loaded} imagens not_drowsy carregadas\")\n",
    "    \n",
    "    # Converter para numpy arrays\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"Total de imagens carregadas: {len(X)}\")\n",
    "    print(f\"Drowsy: {np.sum(y == 1)}, Not Drowsy: {np.sum(y == 0)}\")\n",
    "    \n",
    "    # Dividir em treino e teste (80:20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Drowsiness - Treino: {X_train.shape}, Teste: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def prepare_data_for_training(X_train, y_train, X_test, y_test, task):\n",
    "    \"\"\"\n",
    "    Prepara os dados para treinamento (sem normalização de pixels, seguindo o artigo)\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train, X_test, y_test: dados brutos\n",
    "        task: 'drowsiness' ou 'distraction'\n",
    "    \n",
    "    Returns:\n",
    "        (X_train, y_train, X_test, y_test): dados preparados\n",
    "    \"\"\"\n",
    "    \n",
    "    # IMPORTANTE: Sem normalização de pixels (0-255 mantidos conforme artigo)\n",
    "    # Apenas converter para float32 para compatibilidade com TensorFlow\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    \n",
    "    if task == 'distraction':\n",
    "        # Para classificação multi-classe: converter para categorical\n",
    "        y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "    elif task == 'drowsiness':\n",
    "        # Para classificação binária: manter como está (0 ou 1)\n",
    "        pass\n",
    "    \n",
    "    print(f\"Dados preparados - X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Dados preparados - X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "    print(f\"Range de pixels mantido: {X_train.min():.0f}-{X_train.max():.0f} (conforme artigo)\")\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def train_model(task, dataset_path, epochs=50, batch_size=32, model_save_path=None, max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Função principal para treinar o modelo\n",
    "    \n",
    "    Args:\n",
    "        task: 'drowsiness' ou 'distraction'\n",
    "        dataset_path: caminho para o dataset\n",
    "        epochs: número de épocas\n",
    "        batch_size: tamanho do batch\n",
    "        model_save_path: caminho para salvar o modelo (opcional)\n",
    "        max_images_per_class: limite de imagens por classe para desenvolvimento/teste (None = todas)\n",
    "    \n",
    "    Returns:\n",
    "        (model, history): modelo treinado e histórico\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"=== INICIANDO TREINAMENTO - TAREFA: {task.upper()} ===\")\n",
    "    \n",
    "    if max_images_per_class:\n",
    "        print(f\"MODO DESENVOLVIMENTO: Limitado a {max_images_per_class} imagens por classe\")\n",
    "    else:\n",
    "        print(\"MODO COMPLETO: Usando todas as imagens disponíveis\")\n",
    "    \n",
    "    # Carregar dados específicos para cada tarefa\n",
    "    if task == 'distraction':\n",
    "        X_train, y_train, X_test, y_test = load_state_farm_data(dataset_path, max_images_per_class)\n",
    "    elif task == 'drowsiness':\n",
    "        X_train, y_train, X_test, y_test = load_drowsiness_data(dataset_path, max_images_per_class=max_images_per_class)\n",
    "    else:\n",
    "        raise ValueError(\"task deve ser 'drowsiness' ou 'distraction'\")\n",
    "    \n",
    "    # Preparar dados\n",
    "    X_train, y_train, X_test, y_test = prepare_data_for_training(\n",
    "        X_train, y_train, X_test, y_test, task\n",
    "    )\n",
    "    \n",
    "    # Criar modelo\n",
    "    input_shape = X_train.shape[1:]  # Pega shape das imagens automaticamente\n",
    "    print(f\"Input shape: {input_shape}\")\n",
    "    \n",
    "    model = custom_cnn(input_shape=input_shape, task=task)\n",
    "    \n",
    "    # Mostrar resumo do modelo\n",
    "    print(\"\\n=== ARQUITETURA DO MODELO ===\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks (sem validação, seguindo o artigo)\n",
    "    callbacks = []\n",
    "    \n",
    "    if model_save_path:\n",
    "        # Salvar melhor modelo baseado na accuracy de teste\n",
    "        callbacks.append(\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=model_save_path,\n",
    "                monitor='loss',  # Como não temos validação, monitora loss de treino\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                verbose=1\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n=== INICIANDO TREINAMENTO ===\")\n",
    "    print(f\"Epochs: {epochs}, Batch Size: {batch_size}\")\n",
    "    \n",
    "    # Treinar modelo (sem validation_data, seguindo especificação do artigo)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== AVALIANDO NO CONJUNTO DE TESTE ===\")\n",
    "    # Avaliar no conjunto de teste\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)[:2]\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Exemplo de uso:\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # MODO DESENVOLVIMENTO - Teste rápido com poucos dados\n",
    "    print(\"=== MODO DESENVOLVIMENTO - TESTE RÁPIDO ===\")\n",
    "    \n",
    "    # Treinar modelo de sonolência com apenas 100 imagens por classe\n",
    "    model_drowsiness_dev, history_dev = train_model(\n",
    "        task='drowsiness',\n",
    "        dataset_path='driver_drowsiness_dataset',\n",
    "        epochs=5,  # Menos épocas para teste\n",
    "        batch_size=16,  # Batch menor para teste\n",
    "        max_images_per_class=100,  # Apenas 100 imagens por classe\n",
    "        model_save_path='dev_drowsiness_model.h5'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # MODO COMPLETO - Treinamento final\n",
    "    print(\"=== MODO COMPLETO - TREINAMENTO FINAL ===\")\n",
    "    \n",
    "    # Treinar modelo de detecção de sonolência com dataset completo\n",
    "    model_drowsiness, history_drowsiness = train_model(\n",
    "        task='drowsiness',\n",
    "        dataset_path='driver_drowsiness_dataset',\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        max_images_per_class=None,  # Usar todas as imagens\n",
    "        model_save_path='best_drowsiness_model.h5'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Treinar modelo de classificação de distração\n",
    "    model_distraction, history_distraction = train_model(\n",
    "        task='distraction',\n",
    "        dataset_path='state_farm_driver_detection',\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        max_images_per_class=None,  # Usar todas as imagens\n",
    "        model_save_path='best_distraction_model.h5'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
